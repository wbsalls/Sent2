granule_folder <- list.files(granule_dir)[grep(unique(mu_pts_img@data$MGRS_TILE), list.files(granule_dir))]
#"Warning messages: In grep(unique(mu_pts_img@data$MGRS_TILE), list.files(granule_dir)) : argument 'pattern' has length > 1 and only the first element will be used"
qi_data <- list.files(file.path(granule_dir, granule_folder, "QI_DATA"), pattern = ".gml")
cloud_file <- qi_data[grep("MSK_CLOUDS", qi_data)]
layers <- ogrListLayers(file.path(granule_dir, granule_folder, "QI_DATA", cloud_file))
n_layers <- length(layers)
# if the layer exists: load cloud mask; get point indices falling on cloud; remove these points
if (length(layers) == 1) {
gml <- readOGR(file.path(granule_dir, granule_folder, "QI_DATA", cloud_file), "MaskFeature",
disambiguateFIDs = TRUE, verbose = FALSE)
# assign crs to cloud mask if missing (which it always seems to be)
if (is.na(crs(gml))) {
missing_crs <- "missing crs"
crs(gml) <- crs(mu_pts_img_proj)
}
# query cloud mask value at locations of points
cloud_pts_index <- over(mu_pts_img_proj, gml)
# only include points with extracted value of NA (meaning they don't fall over a cloud)
mu_pts_img_proj <- mu_pts_img_proj[is.na(cloud_pts_index$gml_id), ]
cloudy_pts <- rbind(cloudy_pts, mu_pts_img_proj@data[!is.na(cloud_pts_index$gml_id), ])
if (nrow(mu_pts_img_proj@data[!is.na(cloud_pts_index$gml_id), ]) > 0) {
print("cloud")
}
}
# extract mci values and add as new column
mci_vals <- extract(mci_i, mu_pts_img_proj)
mu_pts_img_proj$mci <- mci_vals
# append these points to mu_mci df
mu_mci <- rbind(mu_mci, mu_pts_img_proj@data)
# update img_summary dataframe
img_summary <- rbind(img_summary, data.frame(img = mci_imgs[i],
n_layers = n_layers,
missing_crs = missing_crs,
n_pts_tot = nrow(mu_pts_img@data),
n_pts_cloudy = nrow(mu_pts_img@data) - nrow(mu_pts_img_proj@data),
n_pts_noncloudy = nrow(mu_pts_img_proj@data)))
}
warnings()
grep(unique(mu_pts_img@data$MGRS_TILE)
granule_folder
list.files(granule_dir)
granule_dir
unique(mu_pts_img@data$MGRS_TILE)
list.files(granule_dir)
unique(mu_pts_img@data$PRODUCT_ID)
samps <- read.csv("O:/PRIV/NERL_ORD_CYAN/Salls_working/Economics/result_station_inLakes_100mBuff.csv")
samps_surf <- samps[samps$ActivityMediaSubdivisionName == "Surface Water", ]
length(unique(samps_surf$COMID))
samps_subset <- samps[samps$ActivityMediaSubdivisionName %in% c("Surface Water"), ]
length(unique(samps_subset$COMID))
table(samps$ActivityMediaSubdivisionName)
table(samps$ActivityMediaSubdivisionName)
nrow(samps)
length(samps$ActivityMediaSubdivisionName == "")
sum(samps$ActivityMediaSubdivisionName == "")
samps_subset <- samps[samps$ActivityMediaSubdivisionName %in% c("Surface Water", "Estuary", ""), ]
length(unique(samps_subset$COMID))
length(unique(samps$COMID))
as.data.frame(table(samps$ActivityMediaSubdivisionName))
length(unique(samps_subset$COMID))
samps_subset <- samps[which(samps$ActivityMediaSubdivisionName %in% c("Surface Water", "Estuary")), ]
length(unique(samps_subset$COMID))
samps_subset <- samps[which(samps$ActivityMediaSubdivisionName %in% c("Surface Water")), ]
length(unique(samps_subset$COMID))
samps_surf <- samps[samps$ActivityMediaSubdivisionName == "Surface Water", ]
length(unique(samps_surf$COMID))
samps_subset <- samps[which(samps$ActivityMediaSubdivisionName %in% c("Surface Water", "Water")), ]
length(unique(samps_subset$COMID))
samps_subset <- samps[which(samps$ActivityMediaSubdivisionName %in% c("Surface Water", "Water", "")), ]
length(unique(samps_subset$COMID))
length(unique(samps$COMID))
samps_subset <- samps[which(samps$ActivityMediaSubdivisionName %in% c("Surface Water", "", "")), ]
length(unique(samps_subset$COMID))
samps_subset <- samps[which(samps$ActivityMediaSubdivisionName %in% c("Surface Water", "Water")), ]
length(unique(samps_subset$COMID))
samps_subset <- samps[which(samps$ActivityMediaSubdivisionName %in% c("Surface Water", "Water", "")), ]
length(unique(samps_subset$COMID))
samps_subset <- samps[which(samps$ActivityMediaSubdivisionName %in% c("Surface Water", "Estuary")), ]
length(unique(samps_subset$COMID))
colnames(samps)
table(samps$ActivityMediaName)
library(rgdal)
lakes <- readOGR("O:/PRIV/NERL_ORD_CYAN/Salls_working/geospatial_general/resolvableLakes/geospatial", "lakes_900m_GLB_noOverlap")
dat <- read.csv("O:/PRIV/NERL_ORD_CYAN/Salls_working/GLB/Analysis/GLB_LandscapeAnalysis_data_clean_2018-08-15.csv")
length(unique(dat$comid))
lakes_in <- lakes[which(lakes$COMID %in% dat$comid), ]
sum(lakes_in$COMID %in% dat$comid)
sum(dat$comid %in% lakes_in$COMID)
?writeOGR
writeOGR(lakes_in, "O:\PRIV\NERL_ORD_CYAN\Salls_working\GLB\geospatial_final", "lakes_369", "ESRI Shapefile")
writeOGR(lakes_in, "O:/PRIV/NERL_ORD_CYAN/Salls_working/GLB/geospatial_final", "lakes_369", "ESRI Shapefile")
library(chron)
library(colorRamps)
library(grDevices)
library(RColorBrewer)
source("C:/Users/WSalls/Desktop/Git/Sent2/error_metrics_1800611.R")
#source("/Users/wilsonsalls/Desktop/Git/Sent2/error_metrics_1800611.R")
#mu_mci_raw <- mu_mci
mu_mci_raw <- read.csv("O:/PRIV/NERL_ORD_CYAN/Sentinel2/Validation/682_imgs/validation_S2_682imgs_MCI_L1C_2018-10-10.csv", stringsAsFactors = FALSE)
#mu_mci_raw <- read.csv("/Users/wilsonsalls/Desktop/EPA/Sentinel2/Validation/682_imgs/validation_S2_682imgs_MCI_L1C_2018-10-10.csv", stringsAsFactors = FALSE)
# remove duplicates: identify based on duplicated chlorophyll-a and MCI (L1C)
val_df <- data.frame(mu_mci_raw$chla_corr, mu_mci_raw$MCI_L1C, mu_mci_raw$LatitudeMeasure, mu_mci_raw$LongitudeMeasure)
sum(duplicated(val_df))
val_df_dups <- val_df[duplicated(val_df), ]
mu_mci <- mu_mci_raw[!duplicated(val_df), ]
# most duplicates have 0 MCI_L1C
#* fix chron
mu_mci$samp_localTime <- chron(dates. = substr(mu_mci$samp_localTime, 2, 9),
times. = substr(mu_mci$samp_localTime, 11, 18))
mu_mci$img_localTime <- chron(dates. = substr(mu_mci$img_localTime, 2, 9),
times. = substr(mu_mci$img_localTime, 11, 18))
mu_mci$offset_hrs <- as.numeric(mu_mci$samp_localTime - mu_mci$img_localTime) * 24
# for plotting color
mu_mci$offset_days_factor <- as.factor(mu_mci$offset_days)
length(levels(mu_mci$offset_days_factor))
jcolors <- data.frame(day = levels(mu_mci$offset_days_factor),
color = I(topo.colors(11, alpha = 0.5)))
#
## calc chl a from MCI  ---------------
slope.mci <- 0.0004 # from Binding et al. 2013 - Erie
intercept.mci <- -0.0021 # from Binding et al. 2013 - Erie
mu_mci$chla_s2 <- (mu_mci$MCI_L1C - intercept.mci) / slope.mci
mu_mci <- mu_mci[mu_mci$chla_s2 > 0, ] # remove calculated negatives -617 (depends on coefficients used)
mu_mci$residual_chla <- abs(mu_mci$chla_s2 - mu_mci$chla_corr) # residual
mu_mci$pct_error_chla <- (abs(mu_mci$chla_s2 - mu_mci$chla_corr) / mu_mci$chla_corr) * 100 # % error
## subset ---------------
# remove land-adjacent
#mu_mci <- mu_mci[mu_mci$dist_shore_m >= 30, ]
# remove NAs
sum(is.na(mu_mci$MCI_L1C))
mu_mci <- mu_mci[!is.na(mu_mci$MCI_L1C), ]
# remove 0s (NA MCI_L1C)
sum(mu_mci$MCI_L1C == 0)
mu_mci <- mu_mci[mu_mci$MCI_L1C != 0, ]
# remove outliers
max(mu_mci$MCI_L1C)
sum(mu_mci$MCI_L1C == max(mu_mci$MCI_L1C))
mu_mci <- mu_mci[mu_mci$MCI_L1C != max(mu_mci$MCI_L1C), ]
min(mu_mci$MCI_L1C)
sum(mu_mci$MCI_L1C < -0.01)
mu_mci <- mu_mci[mu_mci$MCI_L1C > -0.01, ]
sum(mu_mci$chla_corr > 200)
mu_mci <- mu_mci[mu_mci$chla_corr < 200, ] # **** discuss
# export filtered validation data set
#write.csv(mu_mci, sprintf("O:/PRIV/NERL_ORD_CYAN/Sentinel2/Validation/682_imgs/validation_S2_682imgs_MCI_Chla_filtered_%s.csv", Sys.Date()))
mu_mci_filtered <- mu_mci # for resetting data
# subset by offset time
mu_mci <- mu_mci_filtered
offset_min <- 0
offset_max <- 10
offset_threshold <- offset_min:offset_max
mu_mci <- mu_mci[mu_mci$offset_days %in% offset_threshold, ]
#mu_mci_raw <- mu_mci
mu_mci_raw <- read.csv("O:/PRIV/NERL_ORD_CYAN/Sentinel2/Validation/619_imgs_error682/validation_S2_682imgs_MCI_L1C_2018-10-10.csv", stringsAsFactors = FALSE)
# remove duplicates: identify based on duplicated chlorophyll-a and MCI (L1C)
val_df <- data.frame(mu_mci_raw$chla_corr, mu_mci_raw$MCI_L1C, mu_mci_raw$LatitudeMeasure, mu_mci_raw$LongitudeMeasure)
sum(duplicated(val_df))
val_df_dups <- val_df[duplicated(val_df), ]
mu_mci <- mu_mci_raw[!duplicated(val_df), ]
# most duplicates have 0 MCI_L1C
#* fix chron
mu_mci$samp_localTime <- chron(dates. = substr(mu_mci$samp_localTime, 2, 9),
times. = substr(mu_mci$samp_localTime, 11, 18))
mu_mci$img_localTime <- chron(dates. = substr(mu_mci$img_localTime, 2, 9),
times. = substr(mu_mci$img_localTime, 11, 18))
mu_mci$offset_hrs <- as.numeric(mu_mci$samp_localTime - mu_mci$img_localTime) * 24
# for plotting color
mu_mci$offset_days_factor <- as.factor(mu_mci$offset_days)
length(levels(mu_mci$offset_days_factor))
jcolors <- data.frame(day = levels(mu_mci$offset_days_factor),
color = I(topo.colors(11, alpha = 0.5)))
#
## calc chl a from MCI  ---------------
slope.mci <- 0.0004 # from Binding et al. 2013 - Erie
intercept.mci <- -0.0021 # from Binding et al. 2013 - Erie
mu_mci$chla_s2 <- (mu_mci$MCI_L1C - intercept.mci) / slope.mci
mu_mci <- mu_mci[mu_mci$chla_s2 > 0, ] # remove calculated negatives -617 (depends on coefficients used)
mu_mci$residual_chla <- abs(mu_mci$chla_s2 - mu_mci$chla_corr) # residual
mu_mci$pct_error_chla <- (abs(mu_mci$chla_s2 - mu_mci$chla_corr) / mu_mci$chla_corr) * 100 # % error
## subset ---------------
# remove land-adjacent
#mu_mci <- mu_mci[mu_mci$dist_shore_m >= 30, ]
# remove NAs
sum(is.na(mu_mci$MCI_L1C))
mu_mci <- mu_mci[!is.na(mu_mci$MCI_L1C), ]
# remove 0s (NA MCI_L1C)
sum(mu_mci$MCI_L1C == 0)
mu_mci <- mu_mci[mu_mci$MCI_L1C != 0, ]
# remove outliers
max(mu_mci$MCI_L1C)
sum(mu_mci$MCI_L1C == max(mu_mci$MCI_L1C))
mu_mci <- mu_mci[mu_mci$MCI_L1C != max(mu_mci$MCI_L1C), ]
min(mu_mci$MCI_L1C)
sum(mu_mci$MCI_L1C < -0.01)
mu_mci <- mu_mci[mu_mci$MCI_L1C > -0.01, ]
sum(mu_mci$chla_corr > 200)
mu_mci <- mu_mci[mu_mci$chla_corr < 200, ] # **** discuss
# export filtered validation data set
#write.csv(mu_mci, sprintf("O:/PRIV/NERL_ORD_CYAN/Sentinel2/Validation/682_imgs/validation_S2_682imgs_MCI_Chla_filtered_%s.csv", Sys.Date()))
mu_mci_filtered <- mu_mci # for resetting data
# subset by offset time
mu_mci <- mu_mci_filtered
offset_min <- 0
offset_max <- 10
offset_threshold <- offset_min:offset_max
mu_mci <- mu_mci[mu_mci$offset_days %in% offset_threshold, ]
boxplot(dist_shore_m ~ ResultAnalyticalMethod.MethodIdentifierContext, data = mu_mci,
ylab = "distance from shore (m)",
xlab = "Method Identifier Context")
text(0.7, 150, paste0("n = ", table(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext)[1]))
text(1.7, 150, paste0("n = ", table(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext)[2]))
text(2.7, 150, paste0("n = ", table(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext)[3]))
text(0.7, 14000, paste0("n = ", table(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext)[1]))
# shore dist vs method
boxplot(dist_shore_m ~ ResultAnalyticalMethod.MethodIdentifierContext, data = mu_mci,
ylab = "distance from shore (m)",
xlab = "Method Identifier Context")
text(0.7, 14000, paste0("n = ", table(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext)[1]))
text(1.7, 14000, paste0("n = ", table(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext)[2]))
text(2.7, 14000, paste0("n = ", table(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext)[3]))
# investigate patterns ---------------------------------------------------------------------------
par()$mfrow
## shore dist
plot(mu_mci$dist_shore_m, mu_mci$residual_chla,
xlim = c(0, 1000), # try removing this too
#ylim = c(0, 200),
xlab = "distance from shore (m)",
ylab = "chl a error (ug/L)",
pch = 20,
col = alpha("black", alpha = 0.4))
# boxplot
mu_mci$dist_shore_m_interval <- cut(mu_mci$dist_shore_m, seq(0, 2000, 50))
barplot(table(mu_mci$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency")
boxplot(residual_chla ~ dist_shore_m_interval, data = mu_mci,
xlab = "distance from shore (m)",
ylab = "chl a residual")
table(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext)
barplot(table(mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "APHA"), ]$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency", main = "APHA")
barplot(table(mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "EPA"), ]$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency", main = "EPA")
barplot(table(mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USGS"), ]$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency", main = "USGS")
barplot(table(mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USEPA"), ]$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency", main = "USEPA")
barplot(table(mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USGS"), ]$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency", main = "USGS")
mu_usgs <- mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USGS"), ]
plot(mu_usgs$dist_shore_m, mu_usgs$residual_chla)
?lm
m_usgs <- lm(residual_chla ~ dist_shore_m, mu_usgs)
summary(m_usgs)
abline(23.747400, -0.002855)
par(mfrow = c(2,1))
barplot(table(mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "APHA"), ]$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency", main = "APHA")
boxplot(residual_chla ~ dist_shore_m_interval, data = mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "APHA"), ],
xlab = "distance from shore (m)",
ylab = "chl a residual")
barplot(table(mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USEPA"), ]$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency", main = "USEPA")
boxplot(residual_chla ~ dist_shore_m_interval, data = mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USEPA"), ],
xlab = "distance from shore (m)",
ylab = "chl a residual")
nrow(mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USEPA"), ])
barplot(table(mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USGS"), ]$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency", main = "USGS")
boxplot(residual_chla ~ dist_shore_m_interval, data = mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USGS"), ],
xlab = "distance from shore (m)",
ylab = "chl a residual")
mu_mci <- mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USEPA"), ]
library(sp)
library(rgdal)
library(raster)
# make spdf of matchups
lon <- mu_mci$LongitudeMeasure # **
lat <- mu_mci$LatitudeMeasure # **
mu_mci_pts <- SpatialPointsDataFrame(coords = matrix(c(lon, lat), ncol = 2),
mu_mci, proj4string = CRS("+init=epsg:4326"))
# append state name to each point
us <- readOGR("O:/PRIV/NERL_ORD_CYAN/Salls_working/geospatial_general/US", "cb_2015_us_state_20m")
mu_mci_pts_proj <- spTransform(mu_mci_pts, crs(us))
conus <- us[-which(us$STUSPS %in% c("AK", "HI", "PR")), ]
library(scales) # for alpha transparency
plot(conus, col = "cornsilk", border = "grey", main = sprintf("+/- %s-day matchups", offset_max))
#plot(conus, col = "cornsilk", border = "grey", main = sprintf("+/- %s-%s-day matchups", offset_min, offset_max))
plot(mu_mci_pts_proj, pch = 20, col = alpha("black", 0.2), add=TRUE)
colnames(mu_mci)
table(mu_mci$ActivityMediaSubdivisionName)
table(mu_mci$"ActivityIdentifier"
[116] "ActivityTypeCode"
[117] "ActivityMediaName"
[118] "ActivityMediaSubdivisionName" )
table(mu_mci$ActivityTypeCode)
table(mu_mci$ActivityMediaName)
table(mu_mci$MonitoringLocationTypeName)
# subset by offset time
mu_mci <- mu_mci_filtered # reset
table(mu_mci$MonitoringLocationTypeName)
sum(is.na(mu_mci$dist_shore_m))
table(mu_mci$ActivityTypeCode)
mu_method <- mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USEPA"), ]
mu_method$samp_localTime
table(mu_method$samp_localTime)
table(mu_method$samp_localTime, mu_method$LatitudeMeasure)
table(mu_method$samp_localTime, mu_method$chla_corr)
raw <- list.files("D:/s2/raw")
mci <- list.files("D:/s2/mci_resample20", pattern = ".data")
head(raw)
head(mci)
substr("mci_resample20_S2A_MSIL1C_20170223T165311_N0204_R026_T15RTN_20170223T165747", 12, 68)
substr("mci_resample20_S2A_MSIL1C_20170223T165311_N0204_R026_T15RTN_20170223T165747", 16, 68)
nchar("mci_resample20_S2A_MSIL1C_20170223T165311_N0204_R026_T15RTN_20170223T165747")
substr("mci_resample20_S2A_MSIL1C_20170223T165311_N0204_R026_T15RTN_20170223T165747", 16, 71)
mci <- substr(mci, 16, 71)
mci <- list.files("D:/s2/mci_resample20", pattern = ".data")
mcis <- substr(mci, 16, 71)
substr("S2A_MSIL1C_20170223T165311_N0204_R026_T15RTN_20170223T165747.SAFE", 1, 64)
substr("S2A_MSIL1C_20170223T165311_N0204_R026_T15RTN_20170223T165747.SAFE", 1, 61)
substr("S2A_MSIL1C_20170223T165311_N0204_R026_T15RTN_20170223T165747.SAFE", 1, 60)
raws <- substr(raw, 1, 60)
sum(raws %in% mcis)
raws[1]
mcis[1]
?sub
mcis <- sub("mci_resample20_", "", sub(".data", "", mci)
)
raws <- sub(".SAFE". "", raw)
raws <- sub(".SAFE", "", raw)
mcis <- sub("mci_resample20_", "", sub(".data", "", mci))
sum(raws %in% mcis)
raws[which(!(raws %in% mcis))]
length(unique(raws))
length(unique(mcis))
mcis[which(!(mcis %in% raws))]
mu_mci <- read.csv("O:/PRIV/NERL_ORD_CYAN/Sentinel2/Validation/681_imgs/mu_mci_finalset_2019-05-08.csv", stringsAsFactors = FALSE)
## glint ---------
boxplot(error_chla ~ glint, data = mu_mci,
ylab = "chl a residual",
xlab = "Satellite")
table(mu_mci$glint)
# read us shp for state names
us <- readOGR("O:/PRIV/NERL_ORD_CYAN/Salls_working/geospatial_general/US", "cb_2015_us_state_20m")
us <- readOGR("/Users/wilsonsalls/Desktop/EPA/geosp_general/US", "cb_2015_us_state_20m")
# subset to CONUS
conus <- us[-which(us$STUSPS %in% c("AK", "HI", "PR")), ]
## all points
wqp <- read.csv("O:/PRIV/NERL_ORD_CYAN/Sentinel2/Matchups/WQP/20180710/input.csv")
# make spdf of matchups
lon <- wqp$LongitudeMeasure # **
lat <- wqp$LatitudeMeasure # **
wqp_pts <- SpatialPointsDataFrame(coords = matrix(c(lon, lat), ncol = 2),
wqp, proj4string = CRS("+init=epsg:4326"))
# transform
wqp_pts_proj <- spTransform(wqp_pts, crs(us))
## used points
# make spdf of matchups
lon <- mu_mci$LongitudeMeasure # **
lat <- mu_mci$LatitudeMeasure # **
mu_mci_pts <- SpatialPointsDataFrame(coords = matrix(c(lon, lat), ncol = 2),
mu_mci, proj4string = CRS("+init=epsg:4326"))
#writeOGR(mu_mci_pts, "./geospatial", "mu_mci_filtered_pts", "ESRI Shapefile")
# transform
mu_mci_pts_proj <- spTransform(mu_mci_pts, crs(us))
library(rgdal)
library(sp)
# read us shp for state names
us <- readOGR("O:/PRIV/NERL_ORD_CYAN/Salls_working/geospatial_general/US", "cb_2015_us_state_20m")
us <- readOGR("/Users/wilsonsalls/Desktop/EPA/geosp_general/US", "cb_2015_us_state_20m")
# subset to CONUS
conus <- us[-which(us$STUSPS %in% c("AK", "HI", "PR")), ]
## all points
wqp <- read.csv("O:/PRIV/NERL_ORD_CYAN/Sentinel2/Matchups/WQP/20180710/input.csv")
# make spdf of matchups
lon <- wqp$LongitudeMeasure # **
lat <- wqp$LatitudeMeasure # **
wqp_pts <- SpatialPointsDataFrame(coords = matrix(c(lon, lat), ncol = 2),
wqp, proj4string = CRS("+init=epsg:4326"))
# transform
wqp_pts_proj <- spTransform(wqp_pts, crs(us))
library(raster)
# transform
wqp_pts_proj <- spTransform(wqp_pts, crs(us))
## used points
# make spdf of matchups
lon <- mu_mci$LongitudeMeasure # **
mu_mci <- read.csv("O:/PRIV/NERL_ORD_CYAN/Sentinel2/Validation/681_imgs/mu_mci_finalset_2019-05-08.csv", stringsAsFactors = FALSE)
## used points
# make spdf of matchups
lon <- mu_mci$LongitudeMeasure # **
lat <- mu_mci$LatitudeMeasure # **
mu_mci_pts <- SpatialPointsDataFrame(coords = matrix(c(lon, lat), ncol = 2),
mu_mci, proj4string = CRS("+init=epsg:4326"))
# transform
mu_mci_pts_proj <- spTransform(mu_mci_pts, crs(us))
# plot
plot(conus, col = "grey92", border = "white") # 900 x 625
# plot
plot(conus, col = "grey94", border = "white") # 900 x 625
#plot(wqp_pts_proj, pch = 20, col = alpha("black", 0.2), add=TRUE)
plot(wqp_pts_proj, pch = 20, col = "gray60", add=TRUE)
#plot(mu_mci_pts_proj, pch = 20, col = alpha("red", 0.2), add=TRUE)
plot(mu_mci_pts_proj, pch = 20, col = "black", add=TRUE)
legend("bottomleft", legend=c("WQP point", "WQP point used for validation"),
col=c("gray50", "black"), pch = c(20, 20))
library(raster)
?`plot,Raster,Raster-method`
library(rgdal)
library(sp)
library(rgeos)
# load lakes shapefile
lakes <- readOGR(dsn = file.path("O:/PRIV/NERL_ORD_CYAN/Salls_working/geospatial_general/resolvableLakes/NHD_NLA_shoredist"), # <<<<<<
layer = "nhd_nla_subset_shore_dist")
# load lakes shapefile
lakes <- readOGR(dsn = file.path("O:/PRIV/NERL_ORD_CYAN/Salls_working/geospatial_general/resolvableLakes/NHD_NLA_shoredist"), # <<<<<<
layer = "nhd_nla_subset_shore_dist")
# set resolvable lake minimum threshold (m) and select lakes
# e.g. if OLCI single pixel, 300; if OLCI 3x3 pixels, 900
min_size <- 900 # <<<<<<
lakes_resolvable <- lakes[which(lakes$max_window >= min_size), ]
# load in situ file
insitu <- read.csv("O:/PRIV/NERL_ORD_CYAN/Sentinel2/MatchupsWQP/20180710/input.csv", stringsAsFactors=FALSE) # <<<<<<
# load in situ file
insitu <- read.csv("O:/PRIV/NERL_ORD_CYAN/Sentinel2/Matchups/WQP/20180710/input.csv", stringsAsFactors=FALSE) # <<<<<<
# specify longitude and latitude variable names in in situ file
lon_name <- "LongitudeMeasure" # <<<<<<
lat_name <- "LatitudeMeasure" # <<<<<<
# get coordinates and use to make SpatialPoints object
coords <- coordinates(data.frame(long=insitu[, lon_name], lat=insitu[, lat_name]))
head(coords)
samp_pts <- SpatialPoints(coords, proj4string = CRS("+proj=longlat +datum=WGS84")) # <<<<<< (may need to adjust depending on CRS of in situ coordinates)
# reproject SpatialPoints so it can be used with the lakes shapefiles
samp_pts_albers <- spTransform(samp_pts, proj4string(lakes_resolvable))
crs(samp_pts_albers)
CRS(samp_pts_albers)
CRS(samp_pts)
CRS(lakes)
crs(llakes)
crs(lakes)
projection(lakes)
proj4string(lakes_resolvable)
proj4string(samp_pts_albers)
# convert lake polygons to lines for calculating distance from shore
lakes_lines <- as(lakes_resolvable, "SpatialLines")
# calculate distance from shore
dist_shore_m <- gDistance(samp_pts_albers[1:10], lakes_lines)
dist_shore_m
?gDistance
proj4string(lakes_lines)
proj4string(lakes_lines) == proj4string(samp_pts_albers)
# calculate distance from shore
dist_shore_m <- gDistance(samp_pts_albers[1:10], lakes_lines)
# calculate distance from shore
dist_shore_m <- gDistance(samp_pts_albers[1], lakes_lines)
# calculate distance from shore
dist_shore_m <- gDistance(samp_pts_albers[2], lakes_lines)
# calculate distance from shore
dist_shore_m <- gDistance(samp_pts_albers[2, ], lakes_lines)
# calculate distance from shore
dist_shore_m <- gDistance(samp_pts_albers[10, ], lakes_lines)
length(samp_pts_albers[1:10, ])
class(samp_pts_albers[1:10, ])
# calculate distance from shore
dist_shore_m <- gDistance(samp_pts_albers[1:10, ], lakes_lines)
# calculate distance from shore
dist_shore_m <- gDistance(samp_pts_albers[1:100, ], lakes_lines)
# calculate distance from shore
dist_shore_m <- gDistance(samp_pts_albers[1:10, ], lakes_lines)
matr1 <- matrix(1:12, nrow = 3)
matr1
apply(matr1, 1, sum)
# calculate distance from shore
dist_shore_m <- apply(samp_pts_albers[1:10, ], 2, spgeom2 = lakes_lines)
# calculate distance from shore
dist_shore_m <- apply(samp_pts_albers[1:10, ], 2, gDistance, spgeom2 = lakes_lines)
dim(samp_pts_albers[1:10, ])
samp_pts_albers[1:10, ]
length(samp_pts_albers)
dim(samp_pts_albers)
dist_shore_m <- lapply(samp_pts_albers[1:10, ], gDistance, spgeom2 = lakes_lines)
samp_pts_albers[1:10, ]
samp_pts_albers[1:10, ]
samp_pts_albers@data[1:10, ]
dist_shore_m <- gDistance(samp_pts_albers[1:10, ], lakes_lines, byid = TRUE)
dist_shore_m
dist_shore_m <- sapply(samp_pts_albers[1:10, ], gDistance, spgeom2 = lakes_lines)
dist_shore_m <- lsapply(samp_pts_albers[1:10, ], gDistance, spgeom2 = lakes_lines)
dist_shore_m <- lapply(samp_pts_albers[1:10, ], gDistance, spgeom2 = lakes_lines)
?mapplu
?mapply
dist_shore_m <- mapply(gDistance, samp_pts_albers[1:10, ], MoreArgs = list(spgeom2 = lakes_lines))
?SpatialPointsDataFrame
samp_pts <- SpatialPointsDataFrame(coords,
proj4string = CRS("+proj=longlat +datum=WGS84"), # <<<<<< (may need to adjust depending on CRS of in situ coordinates)
data = insitu)
head(samp_pts@data)
# make new column for shore distance
samp_pts_albers$dist_shore_m <- NA
# make new column for shore distance
samp_pts_albers@data$dist_shore_m <- NA
# reproject SpatialPoints so it can be used with the lakes shapefiles
samp_pts_albers <- spTransform(samp_pts, proj4string(lakes_resolvable))
# make new column for shore distance
samp_pts_albers$dist_shore_m <- NA
head(samp_pts_albers$dist_shore_m)
# calculate distance from shore
for (r in seq_along(samp_pts_albers[1:10, ])) {
dist_shore_m <- gDistance(samp_pts_albers[r, ], lakes_lines)
}
# calculate distance from shore
for (r in seq_along(samp_pts_albers[1:10, ])) {
samp_pts_albers$dist_shore_m[r] <- gDistance(samp_pts_albers[r, ], lakes_lines)
}
samp_pts_albers$dist_shore_m[1:12]
# calculate distance from shore
for (r in seq_along(samp_pts_albers[1:100, ])) {
samp_pts_albers$dist_shore_m[r] <- gDistance(samp_pts_albers[r, ], lakes_lines)
}
samp_pts_albers$dist_shore_m[1:20]
samp_pts_albers$LatitudeMeasure[1:20]
