default(par(mfrow))
par(mfrow)
par()
par()$mfrow
par(mfrow = c(2,1))
# boxplot
mu_mci$offset_hrs_day_interval <- cut(mu_mci$offset_hrs_day, seq(-12, 12, 0.5))
barplot(table(mu_mci$offset_hrs_day_interval), xlab = "offset hour of day", ylab = "frequency")
boxplot(residual_chla ~ offset_hrs_day_interval, data = mu_mci,
xlab = "offset hour of day",
ylab = "chl a residual")
# boxplot
mu_mci$dist_shore_m_interval <- cut(mu_mci$dist_shore_m, seq(0, 2000, 50))
barplot(table(mu_mci$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency")
boxplot(residual_chla ~ dist_shore_m_interval, data = mu_mci,
xlab = "distance from shore (m)",
ylab = "chl a residual")
# boxplot
mu_mci$dist_shore_m_interval <- cut(mu_mci$dist_shore_m, seq(0, 10000, 50))
barplot(table(mu_mci$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency")
boxplot(residual_chla ~ dist_shore_m_interval, data = mu_mci,
xlab = "distance from shore (m)",
ylab = "chl a residual")
library(raster)
library(rgdal)
library(sp)
# query MCI values at in situ points ------------------------------------------------------------------------------------------
mu <- read.csv("O:/PRIV/NERL_ORD_CYAN/Sentinel2/Matchups/out/Matchups_S2_chla_10day_filtered_2018-07-23.csv", stringsAsFactors = FALSE)
#mu <- read.csv("/Users/wilsonsalls/Desktop/EPA/S2/Validation/xxx", stringsAsFactors = FALSE)
# subset to same day (if desired)
#mu_sameday <- mu[mu$offset_days == "same day", ]
# make spdf of matchups
lon <- mu$LongitudeMeasure # **
lat <- mu$LatitudeMeasure # **
mu_pts <- SpatialPointsDataFrame(coords = matrix(c(lon, lat), ncol = 2),
mu, proj4string = CRS("+init=epsg:4326"))
# append state name to each point
us <- readOGR("O:/PRIV/NERL_ORD_CYAN/Salls_working/geospatial_general/US", "cb_2015_us_state_20m")
#us <- readOGR("/Users/wilsonsalls/Desktop/EPA/geosp_general/cb_2016_us_state_20m", "cb_2016_us_state_20m")
mu_pts_states <- spTransform(mu_pts, crs(us))
mu_pts_states$state <- over(mu_pts_states, us)$STUSPS
# append COMID to each point
lakes <- readOGR("O:/PRIV/NERL_ORD_CYAN/Salls_working/geospatial_general/resolvableLakes/geospatial", "resolvableLakes90m")
#lakes <- readOGR("/Users/wilsonsalls/Desktop/EPA/geosp_general/resolvableLakes/intermediate", "resolvableLakes90m")
mu_pts_lakes <- spTransform(mu_pts_states, crs(lakes))
mu_pts_lakes$comid <- over(mu_pts_lakes, lakes)$COMID
mu_pts <- mu_pts_lakes
# write to shapefile, csv
'
mu_pts$modeled_MCI_L1C <- (mu_pts$MCI_L1C + 0.00357) / 0.000222 # chla = 4504.5 * MCI + 16.08 {L1C, extreme negs removed}
#mu_pts$modeled_MCI_L1C <- (mu_pts$MCI_L1C + 0.0054) / 0.000232 # chla = 4310.3 * MCI + 23.27 {L1C, all}
mu_pts$residual_MCI_L1C <- abs(mu_pts$modeled_MCI_L1C - mu_pts$chla_corr)
mu_pts_brief <- mu_pts[, c(9, 60, 6, 194, 195, 188, 196, 197)] # take only relevant columns
mu_pts_brief <- mu_pts_brief[!is.na(mu_pts_brief$MCI_L1C), ] # remove NA
mu_pts_brief <- mu_pts_brief[mu_pts_brief$MCI_L1C == 0, ] # remove bad L1C (0)
mu_pts_brief$uniqueID <- 1:nrow(mu_pts_brief@data)
mu_pts_brief@data <- mu_pts_brief@data[, c(9, 1:8)]
writeOGR(mu_pts_brief, "O:/PRIV/NERL_ORD_CYAN/Sentinel2/Validation/geospatial", "matchups_S2_chla", driver = "ESRI Shapefile")
write.csv(mu_pts_brief@data, "O:/PRIV/NERL_ORD_CYAN/Sentinel2/Validation/validation_S2_50imgs_brief.csv")
'
# location of images
rfolder <- "D:/s2/mci_resample20"
#rfolder <- "/Users/wilsonsalls/Desktop/EPA/S2/Images"
safe_folder <- "D:/s2/raw"
# for naming MCI output column
process_name <- "MCI_L1C"
# check image name matching
mci_imgs <- list.files(rfolder, pattern = "\\.data")
#mci_img_names <- substr(mci_imgs, 16, 75)
mci_img_names <- gsub("mci_resample20_", "", mci_imgs)
mci_img_names <- gsub(".data", "", mci_img_names)
length(unique(mu_pts$PRODUCT_ID))
length(mci_img_names)
sum(mci_img_names %in% mu_pts$PRODUCT_ID)
sum(unique(mu_pts$PRODUCT_ID) %in% mci_img_names)
# run extraction
mu_mci <- data.frame()
img_summary <- data.frame()
cloudy_pts <- data.frame()
#for (i in 1:length(mci_imgs)) {
for (i in 367:429) {
# progress
print(sprintf("image #%s at %s", i, Sys.time()))
# initialize variable for use below
missing_crs <- ""
# subset points to those in this image
mu_pts_img <- mu_pts[mu_pts$PRODUCT_ID == sub(".data", "", sub("mci_resample20_", "", mci_imgs[i])), ]
# load raster
# if mci raster doesn't exist, note in summary file and move to next
if (!("MCI.img" %in% list.files(file.path(rfolder, mci_imgs[i])))) {
print("NO MCI IMAGE!!!")
img_summary <- rbind(img_summary, data.frame(img = mci_imgs[i],
n_layers = 0,
missing_crs = "***NO MCI RASTER***",
n_pts_tot = nrow(mu_pts_img@data),
n_pts_cloudy = 0,
n_pts_noncloudy = 0))
next
}
mci_i <- raster(file.path(rfolder, mci_imgs[i], "MCI.img"))
# if no points, update img_summary and skip to next image
if (length(mu_pts_img) == 0) {
img_summary <- rbind(img_summary, data.frame(img = mci_imgs[i],
n_layers = 0,
missing_crs = missing_crs,
n_pts_tot = nrow(mu_pts_img@data),
n_pts_cloudy = 0,
n_pts_noncloudy = 0))
next
}
# reproject points
mu_pts_img_proj <- spTransform(mu_pts_img, crs(mci_i))
## remove cloudy points
# check layers in cloud mask - should be 1, but at least one file has 0
granule_dir <- file.path(safe_folder, paste0(mci_img_names[i], ".SAFE"), "GRANULE")
granule_folder <- list.files(granule_dir)[grep(unique(mu_pts_img@data$MGRS_TILE), list.files(granule_dir))]
#"Warning messages: In grep(unique(mu_pts_img@data$MGRS_TILE), list.files(granule_dir)) : argument 'pattern' has length > 1 and only the first element will be used"
qi_data <- list.files(file.path(granule_dir, granule_folder, "QI_DATA"), pattern = ".gml")
cloud_file <- qi_data[grep("MSK_CLOUDS", qi_data)]
layers <- ogrListLayers(file.path(granule_dir, granule_folder, "QI_DATA", cloud_file))
n_layers <- length(layers)
# if the layer exists: load cloud mask; get point indices falling on cloud; remove these points
if (length(layers) == 1) {
gml <- readOGR(file.path(granule_dir, granule_folder, "QI_DATA", cloud_file), "MaskFeature",
disambiguateFIDs = TRUE, verbose = FALSE)
# assign crs to cloud mask if missing (which it always seems to be)
if (is.na(crs(gml))) {
missing_crs <- "missing crs"
crs(gml) <- crs(mu_pts_img_proj)
}
# query cloud mask value at locations of points
cloud_pts_index <- over(mu_pts_img_proj, gml)
# only include points with extracted value of NA (meaning they don't fall over a cloud)
mu_pts_img_proj <- mu_pts_img_proj[is.na(cloud_pts_index$gml_id), ]
cloudy_pts <- rbind(cloudy_pts, mu_pts_img_proj@data[!is.na(cloud_pts_index$gml_id), ])
if (nrow(mu_pts_img_proj@data[!is.na(cloud_pts_index$gml_id), ]) > 0) {
print("cloud")
}
}
# extract mci values and add as new column
mci_vals <- extract(mci_i, mu_pts_img_proj)
mu_pts_img_proj$mci <- mci_vals
# append these points to mu_mci df
mu_mci <- rbind(mu_mci, mu_pts_img_proj@data)
# update img_summary dataframe
img_summary <- rbind(img_summary, data.frame(img = mci_imgs[i],
n_layers = n_layers,
missing_crs = missing_crs,
n_pts_tot = nrow(mu_pts_img@data),
n_pts_cloudy = nrow(mu_pts_img@data) - nrow(mu_pts_img_proj@data),
n_pts_noncloudy = nrow(mu_pts_img_proj@data)))
}
warnings()
grep(unique(mu_pts_img@data$MGRS_TILE)
granule_folder
list.files(granule_dir)
granule_dir
unique(mu_pts_img@data$MGRS_TILE)
list.files(granule_dir)
unique(mu_pts_img@data$PRODUCT_ID)
samps <- read.csv("O:/PRIV/NERL_ORD_CYAN/Salls_working/Economics/result_station_inLakes_100mBuff.csv")
samps_surf <- samps[samps$ActivityMediaSubdivisionName == "Surface Water", ]
length(unique(samps_surf$COMID))
samps_subset <- samps[samps$ActivityMediaSubdivisionName %in% c("Surface Water"), ]
length(unique(samps_subset$COMID))
table(samps$ActivityMediaSubdivisionName)
table(samps$ActivityMediaSubdivisionName)
nrow(samps)
length(samps$ActivityMediaSubdivisionName == "")
sum(samps$ActivityMediaSubdivisionName == "")
samps_subset <- samps[samps$ActivityMediaSubdivisionName %in% c("Surface Water", "Estuary", ""), ]
length(unique(samps_subset$COMID))
length(unique(samps$COMID))
as.data.frame(table(samps$ActivityMediaSubdivisionName))
length(unique(samps_subset$COMID))
samps_subset <- samps[which(samps$ActivityMediaSubdivisionName %in% c("Surface Water", "Estuary")), ]
length(unique(samps_subset$COMID))
samps_subset <- samps[which(samps$ActivityMediaSubdivisionName %in% c("Surface Water")), ]
length(unique(samps_subset$COMID))
samps_surf <- samps[samps$ActivityMediaSubdivisionName == "Surface Water", ]
length(unique(samps_surf$COMID))
samps_subset <- samps[which(samps$ActivityMediaSubdivisionName %in% c("Surface Water", "Water")), ]
length(unique(samps_subset$COMID))
samps_subset <- samps[which(samps$ActivityMediaSubdivisionName %in% c("Surface Water", "Water", "")), ]
length(unique(samps_subset$COMID))
length(unique(samps$COMID))
samps_subset <- samps[which(samps$ActivityMediaSubdivisionName %in% c("Surface Water", "", "")), ]
length(unique(samps_subset$COMID))
samps_subset <- samps[which(samps$ActivityMediaSubdivisionName %in% c("Surface Water", "Water")), ]
length(unique(samps_subset$COMID))
samps_subset <- samps[which(samps$ActivityMediaSubdivisionName %in% c("Surface Water", "Water", "")), ]
length(unique(samps_subset$COMID))
samps_subset <- samps[which(samps$ActivityMediaSubdivisionName %in% c("Surface Water", "Estuary")), ]
length(unique(samps_subset$COMID))
colnames(samps)
table(samps$ActivityMediaName)
library(rgdal)
lakes <- readOGR("O:/PRIV/NERL_ORD_CYAN/Salls_working/geospatial_general/resolvableLakes/geospatial", "lakes_900m_GLB_noOverlap")
dat <- read.csv("O:/PRIV/NERL_ORD_CYAN/Salls_working/GLB/Analysis/GLB_LandscapeAnalysis_data_clean_2018-08-15.csv")
length(unique(dat$comid))
lakes_in <- lakes[which(lakes$COMID %in% dat$comid), ]
sum(lakes_in$COMID %in% dat$comid)
sum(dat$comid %in% lakes_in$COMID)
?writeOGR
writeOGR(lakes_in, "O:\PRIV\NERL_ORD_CYAN\Salls_working\GLB\geospatial_final", "lakes_369", "ESRI Shapefile")
writeOGR(lakes_in, "O:/PRIV/NERL_ORD_CYAN/Salls_working/GLB/geospatial_final", "lakes_369", "ESRI Shapefile")
library(chron)
library(colorRamps)
library(grDevices)
library(RColorBrewer)
source("C:/Users/WSalls/Desktop/Git/Sent2/error_metrics_1800611.R")
#source("/Users/wilsonsalls/Desktop/Git/Sent2/error_metrics_1800611.R")
#mu_mci_raw <- mu_mci
mu_mci_raw <- read.csv("O:/PRIV/NERL_ORD_CYAN/Sentinel2/Validation/682_imgs/validation_S2_682imgs_MCI_L1C_2018-10-10.csv", stringsAsFactors = FALSE)
#mu_mci_raw <- read.csv("/Users/wilsonsalls/Desktop/EPA/Sentinel2/Validation/682_imgs/validation_S2_682imgs_MCI_L1C_2018-10-10.csv", stringsAsFactors = FALSE)
# remove duplicates: identify based on duplicated chlorophyll-a and MCI (L1C)
val_df <- data.frame(mu_mci_raw$chla_corr, mu_mci_raw$MCI_L1C, mu_mci_raw$LatitudeMeasure, mu_mci_raw$LongitudeMeasure)
sum(duplicated(val_df))
val_df_dups <- val_df[duplicated(val_df), ]
mu_mci <- mu_mci_raw[!duplicated(val_df), ]
# most duplicates have 0 MCI_L1C
#* fix chron
mu_mci$samp_localTime <- chron(dates. = substr(mu_mci$samp_localTime, 2, 9),
times. = substr(mu_mci$samp_localTime, 11, 18))
mu_mci$img_localTime <- chron(dates. = substr(mu_mci$img_localTime, 2, 9),
times. = substr(mu_mci$img_localTime, 11, 18))
mu_mci$offset_hrs <- as.numeric(mu_mci$samp_localTime - mu_mci$img_localTime) * 24
# for plotting color
mu_mci$offset_days_factor <- as.factor(mu_mci$offset_days)
length(levels(mu_mci$offset_days_factor))
jcolors <- data.frame(day = levels(mu_mci$offset_days_factor),
color = I(topo.colors(11, alpha = 0.5)))
#
## calc chl a from MCI  ---------------
slope.mci <- 0.0004 # from Binding et al. 2013 - Erie
intercept.mci <- -0.0021 # from Binding et al. 2013 - Erie
mu_mci$chla_s2 <- (mu_mci$MCI_L1C - intercept.mci) / slope.mci
mu_mci <- mu_mci[mu_mci$chla_s2 > 0, ] # remove calculated negatives -617 (depends on coefficients used)
mu_mci$residual_chla <- abs(mu_mci$chla_s2 - mu_mci$chla_corr) # residual
mu_mci$pct_error_chla <- (abs(mu_mci$chla_s2 - mu_mci$chla_corr) / mu_mci$chla_corr) * 100 # % error
## subset ---------------
# remove land-adjacent
#mu_mci <- mu_mci[mu_mci$dist_shore_m >= 30, ]
# remove NAs
sum(is.na(mu_mci$MCI_L1C))
mu_mci <- mu_mci[!is.na(mu_mci$MCI_L1C), ]
# remove 0s (NA MCI_L1C)
sum(mu_mci$MCI_L1C == 0)
mu_mci <- mu_mci[mu_mci$MCI_L1C != 0, ]
# remove outliers
max(mu_mci$MCI_L1C)
sum(mu_mci$MCI_L1C == max(mu_mci$MCI_L1C))
mu_mci <- mu_mci[mu_mci$MCI_L1C != max(mu_mci$MCI_L1C), ]
min(mu_mci$MCI_L1C)
sum(mu_mci$MCI_L1C < -0.01)
mu_mci <- mu_mci[mu_mci$MCI_L1C > -0.01, ]
sum(mu_mci$chla_corr > 200)
mu_mci <- mu_mci[mu_mci$chla_corr < 200, ] # **** discuss
# export filtered validation data set
#write.csv(mu_mci, sprintf("O:/PRIV/NERL_ORD_CYAN/Sentinel2/Validation/682_imgs/validation_S2_682imgs_MCI_Chla_filtered_%s.csv", Sys.Date()))
mu_mci_filtered <- mu_mci # for resetting data
# subset by offset time
mu_mci <- mu_mci_filtered
offset_min <- 0
offset_max <- 10
offset_threshold <- offset_min:offset_max
mu_mci <- mu_mci[mu_mci$offset_days %in% offset_threshold, ]
#mu_mci_raw <- mu_mci
mu_mci_raw <- read.csv("O:/PRIV/NERL_ORD_CYAN/Sentinel2/Validation/619_imgs_error682/validation_S2_682imgs_MCI_L1C_2018-10-10.csv", stringsAsFactors = FALSE)
# remove duplicates: identify based on duplicated chlorophyll-a and MCI (L1C)
val_df <- data.frame(mu_mci_raw$chla_corr, mu_mci_raw$MCI_L1C, mu_mci_raw$LatitudeMeasure, mu_mci_raw$LongitudeMeasure)
sum(duplicated(val_df))
val_df_dups <- val_df[duplicated(val_df), ]
mu_mci <- mu_mci_raw[!duplicated(val_df), ]
# most duplicates have 0 MCI_L1C
#* fix chron
mu_mci$samp_localTime <- chron(dates. = substr(mu_mci$samp_localTime, 2, 9),
times. = substr(mu_mci$samp_localTime, 11, 18))
mu_mci$img_localTime <- chron(dates. = substr(mu_mci$img_localTime, 2, 9),
times. = substr(mu_mci$img_localTime, 11, 18))
mu_mci$offset_hrs <- as.numeric(mu_mci$samp_localTime - mu_mci$img_localTime) * 24
# for plotting color
mu_mci$offset_days_factor <- as.factor(mu_mci$offset_days)
length(levels(mu_mci$offset_days_factor))
jcolors <- data.frame(day = levels(mu_mci$offset_days_factor),
color = I(topo.colors(11, alpha = 0.5)))
#
## calc chl a from MCI  ---------------
slope.mci <- 0.0004 # from Binding et al. 2013 - Erie
intercept.mci <- -0.0021 # from Binding et al. 2013 - Erie
mu_mci$chla_s2 <- (mu_mci$MCI_L1C - intercept.mci) / slope.mci
mu_mci <- mu_mci[mu_mci$chla_s2 > 0, ] # remove calculated negatives -617 (depends on coefficients used)
mu_mci$residual_chla <- abs(mu_mci$chla_s2 - mu_mci$chla_corr) # residual
mu_mci$pct_error_chla <- (abs(mu_mci$chla_s2 - mu_mci$chla_corr) / mu_mci$chla_corr) * 100 # % error
## subset ---------------
# remove land-adjacent
#mu_mci <- mu_mci[mu_mci$dist_shore_m >= 30, ]
# remove NAs
sum(is.na(mu_mci$MCI_L1C))
mu_mci <- mu_mci[!is.na(mu_mci$MCI_L1C), ]
# remove 0s (NA MCI_L1C)
sum(mu_mci$MCI_L1C == 0)
mu_mci <- mu_mci[mu_mci$MCI_L1C != 0, ]
# remove outliers
max(mu_mci$MCI_L1C)
sum(mu_mci$MCI_L1C == max(mu_mci$MCI_L1C))
mu_mci <- mu_mci[mu_mci$MCI_L1C != max(mu_mci$MCI_L1C), ]
min(mu_mci$MCI_L1C)
sum(mu_mci$MCI_L1C < -0.01)
mu_mci <- mu_mci[mu_mci$MCI_L1C > -0.01, ]
sum(mu_mci$chla_corr > 200)
mu_mci <- mu_mci[mu_mci$chla_corr < 200, ] # **** discuss
# export filtered validation data set
#write.csv(mu_mci, sprintf("O:/PRIV/NERL_ORD_CYAN/Sentinel2/Validation/682_imgs/validation_S2_682imgs_MCI_Chla_filtered_%s.csv", Sys.Date()))
mu_mci_filtered <- mu_mci # for resetting data
# subset by offset time
mu_mci <- mu_mci_filtered
offset_min <- 0
offset_max <- 10
offset_threshold <- offset_min:offset_max
mu_mci <- mu_mci[mu_mci$offset_days %in% offset_threshold, ]
boxplot(dist_shore_m ~ ResultAnalyticalMethod.MethodIdentifierContext, data = mu_mci,
ylab = "distance from shore (m)",
xlab = "Method Identifier Context")
text(0.7, 150, paste0("n = ", table(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext)[1]))
text(1.7, 150, paste0("n = ", table(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext)[2]))
text(2.7, 150, paste0("n = ", table(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext)[3]))
text(0.7, 14000, paste0("n = ", table(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext)[1]))
# shore dist vs method
boxplot(dist_shore_m ~ ResultAnalyticalMethod.MethodIdentifierContext, data = mu_mci,
ylab = "distance from shore (m)",
xlab = "Method Identifier Context")
text(0.7, 14000, paste0("n = ", table(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext)[1]))
text(1.7, 14000, paste0("n = ", table(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext)[2]))
text(2.7, 14000, paste0("n = ", table(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext)[3]))
# investigate patterns ---------------------------------------------------------------------------
par()$mfrow
## shore dist
plot(mu_mci$dist_shore_m, mu_mci$residual_chla,
xlim = c(0, 1000), # try removing this too
#ylim = c(0, 200),
xlab = "distance from shore (m)",
ylab = "chl a error (ug/L)",
pch = 20,
col = alpha("black", alpha = 0.4))
# boxplot
mu_mci$dist_shore_m_interval <- cut(mu_mci$dist_shore_m, seq(0, 2000, 50))
barplot(table(mu_mci$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency")
boxplot(residual_chla ~ dist_shore_m_interval, data = mu_mci,
xlab = "distance from shore (m)",
ylab = "chl a residual")
table(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext)
barplot(table(mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "APHA"), ]$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency", main = "APHA")
barplot(table(mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "EPA"), ]$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency", main = "EPA")
barplot(table(mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USGS"), ]$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency", main = "USGS")
barplot(table(mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USEPA"), ]$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency", main = "USEPA")
barplot(table(mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USGS"), ]$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency", main = "USGS")
mu_usgs <- mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USGS"), ]
plot(mu_usgs$dist_shore_m, mu_usgs$residual_chla)
?lm
m_usgs <- lm(residual_chla ~ dist_shore_m, mu_usgs)
summary(m_usgs)
abline(23.747400, -0.002855)
par(mfrow = c(2,1))
barplot(table(mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "APHA"), ]$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency", main = "APHA")
boxplot(residual_chla ~ dist_shore_m_interval, data = mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "APHA"), ],
xlab = "distance from shore (m)",
ylab = "chl a residual")
barplot(table(mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USEPA"), ]$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency", main = "USEPA")
boxplot(residual_chla ~ dist_shore_m_interval, data = mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USEPA"), ],
xlab = "distance from shore (m)",
ylab = "chl a residual")
nrow(mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USEPA"), ])
barplot(table(mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USGS"), ]$dist_shore_m_interval), xlab = "distance from shore (m)", ylab = "frequency", main = "USGS")
boxplot(residual_chla ~ dist_shore_m_interval, data = mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USGS"), ],
xlab = "distance from shore (m)",
ylab = "chl a residual")
mu_mci <- mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USEPA"), ]
library(sp)
library(rgdal)
library(raster)
# make spdf of matchups
lon <- mu_mci$LongitudeMeasure # **
lat <- mu_mci$LatitudeMeasure # **
mu_mci_pts <- SpatialPointsDataFrame(coords = matrix(c(lon, lat), ncol = 2),
mu_mci, proj4string = CRS("+init=epsg:4326"))
# append state name to each point
us <- readOGR("O:/PRIV/NERL_ORD_CYAN/Salls_working/geospatial_general/US", "cb_2015_us_state_20m")
mu_mci_pts_proj <- spTransform(mu_mci_pts, crs(us))
conus <- us[-which(us$STUSPS %in% c("AK", "HI", "PR")), ]
library(scales) # for alpha transparency
plot(conus, col = "cornsilk", border = "grey", main = sprintf("+/- %s-day matchups", offset_max))
#plot(conus, col = "cornsilk", border = "grey", main = sprintf("+/- %s-%s-day matchups", offset_min, offset_max))
plot(mu_mci_pts_proj, pch = 20, col = alpha("black", 0.2), add=TRUE)
colnames(mu_mci)
table(mu_mci$ActivityMediaSubdivisionName)
table(mu_mci$"ActivityIdentifier"
[116] "ActivityTypeCode"
[117] "ActivityMediaName"
[118] "ActivityMediaSubdivisionName" )
table(mu_mci$ActivityTypeCode)
table(mu_mci$ActivityMediaName)
table(mu_mci$MonitoringLocationTypeName)
# subset by offset time
mu_mci <- mu_mci_filtered # reset
table(mu_mci$MonitoringLocationTypeName)
sum(is.na(mu_mci$dist_shore_m))
table(mu_mci$ActivityTypeCode)
mu_method <- mu_mci[which(mu_mci$ResultAnalyticalMethod.MethodIdentifierContext == "USEPA"), ]
mu_method$samp_localTime
table(mu_method$samp_localTime)
table(mu_method$samp_localTime, mu_method$LatitudeMeasure)
table(mu_method$samp_localTime, mu_method$chla_corr)
raw <- list.files("D:/s2/raw")
mci <- list.files("D:/s2/mci_resample20", pattern = ".data")
head(raw)
head(mci)
substr("mci_resample20_S2A_MSIL1C_20170223T165311_N0204_R026_T15RTN_20170223T165747", 12, 68)
substr("mci_resample20_S2A_MSIL1C_20170223T165311_N0204_R026_T15RTN_20170223T165747", 16, 68)
nchar("mci_resample20_S2A_MSIL1C_20170223T165311_N0204_R026_T15RTN_20170223T165747")
substr("mci_resample20_S2A_MSIL1C_20170223T165311_N0204_R026_T15RTN_20170223T165747", 16, 71)
mci <- substr(mci, 16, 71)
mci <- list.files("D:/s2/mci_resample20", pattern = ".data")
mcis <- substr(mci, 16, 71)
substr("S2A_MSIL1C_20170223T165311_N0204_R026_T15RTN_20170223T165747.SAFE", 1, 64)
substr("S2A_MSIL1C_20170223T165311_N0204_R026_T15RTN_20170223T165747.SAFE", 1, 61)
substr("S2A_MSIL1C_20170223T165311_N0204_R026_T15RTN_20170223T165747.SAFE", 1, 60)
raws <- substr(raw, 1, 60)
sum(raws %in% mcis)
raws[1]
mcis[1]
?sub
mcis <- sub("mci_resample20_", "", sub(".data", "", mci)
)
raws <- sub(".SAFE". "", raw)
raws <- sub(".SAFE", "", raw)
mcis <- sub("mci_resample20_", "", sub(".data", "", mci))
sum(raws %in% mcis)
raws[which(!(raws %in% mcis))]
length(unique(raws))
length(unique(mcis))
mcis[which(!(mcis %in% raws))]
mu_mci <- read.csv("O:/PRIV/NERL_ORD_CYAN/Sentinel2/Validation/681_imgs/mu_mci_finalset_2019-05-08.csv", stringsAsFactors = FALSE)
## glint ---------
boxplot(error_chla ~ glint, data = mu_mci,
ylab = "chl a residual",
xlab = "Satellite")
table(mu_mci$glint)
# read us shp for state names
us <- readOGR("O:/PRIV/NERL_ORD_CYAN/Salls_working/geospatial_general/US", "cb_2015_us_state_20m")
us <- readOGR("/Users/wilsonsalls/Desktop/EPA/geosp_general/US", "cb_2015_us_state_20m")
# subset to CONUS
conus <- us[-which(us$STUSPS %in% c("AK", "HI", "PR")), ]
## all points
wqp <- read.csv("O:/PRIV/NERL_ORD_CYAN/Sentinel2/Matchups/WQP/20180710/input.csv")
# make spdf of matchups
lon <- wqp$LongitudeMeasure # **
lat <- wqp$LatitudeMeasure # **
wqp_pts <- SpatialPointsDataFrame(coords = matrix(c(lon, lat), ncol = 2),
wqp, proj4string = CRS("+init=epsg:4326"))
# transform
wqp_pts_proj <- spTransform(wqp_pts, crs(us))
## used points
# make spdf of matchups
lon <- mu_mci$LongitudeMeasure # **
lat <- mu_mci$LatitudeMeasure # **
mu_mci_pts <- SpatialPointsDataFrame(coords = matrix(c(lon, lat), ncol = 2),
mu_mci, proj4string = CRS("+init=epsg:4326"))
#writeOGR(mu_mci_pts, "./geospatial", "mu_mci_filtered_pts", "ESRI Shapefile")
# transform
mu_mci_pts_proj <- spTransform(mu_mci_pts, crs(us))
library(rgdal)
library(sp)
# read us shp for state names
us <- readOGR("O:/PRIV/NERL_ORD_CYAN/Salls_working/geospatial_general/US", "cb_2015_us_state_20m")
us <- readOGR("/Users/wilsonsalls/Desktop/EPA/geosp_general/US", "cb_2015_us_state_20m")
# subset to CONUS
conus <- us[-which(us$STUSPS %in% c("AK", "HI", "PR")), ]
## all points
wqp <- read.csv("O:/PRIV/NERL_ORD_CYAN/Sentinel2/Matchups/WQP/20180710/input.csv")
# make spdf of matchups
lon <- wqp$LongitudeMeasure # **
lat <- wqp$LatitudeMeasure # **
wqp_pts <- SpatialPointsDataFrame(coords = matrix(c(lon, lat), ncol = 2),
wqp, proj4string = CRS("+init=epsg:4326"))
# transform
wqp_pts_proj <- spTransform(wqp_pts, crs(us))
library(raster)
# transform
wqp_pts_proj <- spTransform(wqp_pts, crs(us))
## used points
# make spdf of matchups
lon <- mu_mci$LongitudeMeasure # **
mu_mci <- read.csv("O:/PRIV/NERL_ORD_CYAN/Sentinel2/Validation/681_imgs/mu_mci_finalset_2019-05-08.csv", stringsAsFactors = FALSE)
## used points
# make spdf of matchups
lon <- mu_mci$LongitudeMeasure # **
lat <- mu_mci$LatitudeMeasure # **
mu_mci_pts <- SpatialPointsDataFrame(coords = matrix(c(lon, lat), ncol = 2),
mu_mci, proj4string = CRS("+init=epsg:4326"))
# transform
mu_mci_pts_proj <- spTransform(mu_mci_pts, crs(us))
# plot
plot(conus, col = "grey92", border = "white") # 900 x 625
# plot
plot(conus, col = "grey94", border = "white") # 900 x 625
#plot(wqp_pts_proj, pch = 20, col = alpha("black", 0.2), add=TRUE)
plot(wqp_pts_proj, pch = 20, col = "gray60", add=TRUE)
#plot(mu_mci_pts_proj, pch = 20, col = alpha("red", 0.2), add=TRUE)
plot(mu_mci_pts_proj, pch = 20, col = "black", add=TRUE)
legend("bottomleft", legend=c("WQP point", "WQP point used for validation"),
col=c("gray50", "black"), pch = c(20, 20))
